{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5d63573-85f8-425e-b325-feecb96de037",
   "metadata": {},
   "source": [
    "# Assimilate GLSD data with DIESEL\n",
    "\n",
    "This notebook runs assimilation of GLSD data using the DIESEL version of the Ensemble Kalman filter. \n",
    "\n",
    "It also compares two assimilation methods (normal vs cell-averaged observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5b5043-2a78-4111-859b-e59950f8947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import dask\n",
    "import pandas as pd\n",
    "import dask.array as da\n",
    "import xarray as xr\n",
    "from climate.utils import load_dataset\n",
    "\n",
    "from dask.distributed import Client, wait, progress                             \n",
    "import diesel as ds                                                             \n",
    "from diesel.scoring import compute_RE_score, compute_CRPS, compute_energy_score \n",
    "from diesel.estimation import localize_covariance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eb785c-8692-41cf-94a4-705d89e4e34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"/storage/homefs/ct19x463/Dev/Climate/Data/\"\n",
    "results_folder = \"/storage/homefs/ct19x463/Dev/Climate/reporting/all_at_once_vs_sequential\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad792b7b-ea36-4515-a2ff-e427f3de441b",
   "metadata": {},
   "source": [
    "## Build Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4abf061-64dd-495c-ba16-78a39ae1d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = ds.cluster.UbelixCluster(n_nodes=12, mem_per_node=64, cores_per_node=3,\n",
    "            partition=\"gpu\", qos=\"job_gpu\")                                     \n",
    "cluster.scale(9)                                                           \n",
    "client = Client(cluster)                                                    \n",
    "                                                                                \n",
    "# Add to builtins so we have one global client.\n",
    "# Note that this is necessary before importing the EnsembleKalmanFilter module, so that the module is aware of the cluster.\n",
    "__builtins__.CLIENT = client                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f22768-5a73-4a98-84c7-b2e108260860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diesel.kalman_filtering import EnsembleKalmanFilter \n",
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10014e1-c7bd-4096-a316-847918c128a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287f852a-e1b8-4ea2-8b7a-42f95c9836ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOT_ENSEMBLES_NUMBER = 30\n",
    "(dataset_mean, dataset_members,\n",
    "    dataset_instrumental, dataset_reference,\n",
    "    dataset_members_zarr)= load_dataset(\n",
    "    base_folder, TOT_ENSEMBLES_NUMBER, ignore_members=True)\n",
    "print(\"Loading done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86679073-abd2-4df3-9564-98c2de441380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from climate.kalman_filter import EnsembleKalmanFilterScatter\n",
    "helper_filter = EnsembleKalmanFilterScatter(dataset_mean, dataset_members_zarr, dataset_instrumental, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f204b16-4c4d-4e3d-b716-91eca1f918b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df37b317-bad4-43e0-8a8b-8d38bc1e1f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assimilation_date = '1990-10-16'\n",
    "mean_ds = helper_filter.dataset_mean.get_window_vector(assimilation_date, assimilation_date, variable='temperature')\n",
    "ensemble_ds = helper_filter.dataset_members.get_window_vector(assimilation_date, assimilation_date, variable='temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf20e964-9f54-492c-9f94-74c9135ce4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ds, ensemble_ds = client.persist(mean_ds), client.persist(ensemble_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb2aae-94f0-4bc8-ae37-5ff66317154b",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f036dd-4804-43ee-9d6d-a31cb8be8b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = int(assimilation_date[:4])\n",
    "data_df = pd.read_csv(os.path.join(base_folder, \"Instrumental/GLSD/yearly_csv/temperature_{}.csv\".format(year)), index_col=0)\n",
    "data_ds = xr.Dataset.from_dataframe(data_df)\n",
    "\n",
    "# Rename the date variable and make latitude/longitude into coordinates.\n",
    "data_ds = data_ds.rename({'date': 'time'})\n",
    "data_ds = data_ds.set_coords(['time', 'latitude', 'longitude'])\n",
    "data_ds = data_ds['temperature']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dadda0a-b123-49f3-a7d9-fc700590a0f5",
   "metadata": {},
   "source": [
    "## Prepare Forward Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82946c2f-e082-4576-85e4-c8b886fab44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one month.\n",
    "# Note that GLSD uses different reference for month (01 instead of 16), so have to replace.\n",
    "assimilation_date_datasel= assimilation_date[:-2] + '01'\n",
    "data_month_ds = data_ds.where(data_ds.time==assimilation_date_datasel, drop=True)\n",
    "\n",
    "# Need to clean data since dataset contains erroneous measurements, i.e. \n",
    "# either extreme values (10^30) or values that are exactly zero for a given station across time.\n",
    "data_month_ds = data_month_ds.where((data_month_ds > -100.0) & (data_month_ds < 100.0) & (da.abs(data_month_ds) > 0.0001), drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5927c5-eccb-4bae-ac98-d7e289a06344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model cell index corresponding to each observations.\n",
    "from climate.utils import match_vectors_indices\n",
    "matched_inds = match_vectors_indices(mean_ds, data_month_ds)\n",
    "\n",
    "# WARNING: Never try to execute bare loops in DASK, it will exceed the maximal graph depth.\n",
    "G = np.zeros((data_month_ds.shape[0], mean_ds.shape[0]))\n",
    "for obs_nr, model_cell_ind in enumerate(matched_inds):\n",
    "    G[obs_nr, model_cell_ind] = 1.0\n",
    "\n",
    "G = da.from_array(G)\n",
    "G = client.persist(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a7cd43-8512-4bda-ab10-90284807afed",
   "metadata": {},
   "source": [
    "## (Deprecated) Make Filter more stable by only assimilating mean for model cells that contain multiple observations.\n",
    "\n",
    "The idea here is that having multiple (in this case around 50) observations being assimilated in a single model cell can lead to numerical instabilities. \n",
    "We thus work with one observations per cell, being the mean of all the observations. \n",
    "In the end the idea was abandoned, since it only plays a role for the updating of the ensemble members. For the mean everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c9363e-17cf-498f-b650-74bfc5fa2d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_per_cell = da.sum(G, axis=0)\n",
    "obs_per_cell[obs_per_cell == 0] = 1\n",
    "G_norm = G / obs_per_cell\n",
    "G_norm = client.persist(G_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02a1cb4-9127-4bbe-8757-eddceb178a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The operator G_avg contains one single observation per model cell (or zero), which is the average of all observations belonging to that cell.\n",
    "averaged_data = (G_norm.T @ data_month_ds.values).T.compute()\n",
    "G_avg = da.eye(averaged_data.shape[0])\n",
    "G_avg = G_avg[np.flatnonzero(averaged_data), :]\n",
    "d_avg = averaged_data[np.flatnonzero(averaged_data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ef9837-53cb-4675-bd8f-96a6ff8035ef",
   "metadata": {},
   "source": [
    "## Estimate Covariance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28562468-8a1d-4b24-b74a-df0efa7982b7",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Estimate covariance using empirical covariance of the ensemble.       \n",
    "raw_estimated_cov_lazy = ds.estimation.empirical_covariance(ensemble_ds.chunk((1, 1800)))  \n",
    "                                                                                \n",
    "# Persist the covariance on the cluster.                                \n",
    "raw_estimated_cov = client.persist(raw_estimated_cov_lazy) \n",
    "progress(raw_estimated_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201779c0-7dde-4540-b2b8-d8d9a129c297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct (lazy) covariance matrix.                                       \n",
    "lambda0 = 1500 # Localization in kilometers.\n",
    "\n",
    "lengthscales = da.from_array([lambda0])   \n",
    "kernel = ds.covariance.squared_exponential(lengthscales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f807901-aabc-4cd1-87a5-85b5164ca90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform covariance localization.\n",
    "grid_pts = da.vstack([mean_ds.latitude, mean_ds.longitude]).T\n",
    "grid_pts = client.persist(grid_pts.rechunk((1800, 2)))\n",
    "localization_matrix = kernel.covariance_matrix(grid_pts, grid_pts, metric='haversine') \n",
    "localization_matrix = client.persist(localization_matrix)\n",
    "progress(localization_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbca58d-60a5-4e47-8e49-b78326dc314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Here we have added multiplicative inflation.\n",
    "loc_estimated_cov = localize_covariance(raw_estimated_cov, localization_matrix)\n",
    "loc_estimated_cov = client.persist(loc_estimated_cov)\n",
    "progress(loc_estimated_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cecc54b-439a-461c-9a7b-13cb2c419bc8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run Assimilation: All-at-once (aao) vs sequential (seq)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a16286-5995-45b2-bdcd-60cf838f64bd",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Run data assimilation using an ensemble Kalman filter.                \n",
    "my_filter = EnsembleKalmanFilter()                                      \n",
    "\n",
    "data_std = 3.0\n",
    "data_vector = client.persist(da.from_array(data_month_ds.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c52f213-0aa0-4b05-aabf-eef783704e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assimilate all data.\n",
    "mean_updated_aao, _ = my_filter.update_ensemble(\n",
    "    mean_ds.data, ensemble_ds.data, G,\n",
    "    data_vector, data_std, loc_estimated_cov)\n",
    "\n",
    "# Trigger computations and block. Otherwise will clutter the scheduler. \n",
    "mean_updated_aao = client.persist(mean_updated_aao)                \n",
    "# ensemble_updated_one_go_loc = client.persist(ensemble_updated_one_go_loc)\n",
    "# progress(mean_updated_aao) # Block till end of computations.                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf421ff-87fa-43b7-8b26-0ee237215709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the sequential version.\n",
    "mean_updated_seq = my_filter.update_mean_sequential_nondask(\n",
    "    mean_ds.data, G,\n",
    "    data_vector, data_std, loc_estimated_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c296b30c-54b4-467b-b818-a9c1c9b2f8a7",
   "metadata": {},
   "source": [
    "## Compare the different updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e85c269-d963-417e-9908-fbc8c96017bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic plotting functions.\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "import cartopy.crs as ccrs\n",
    "from shapely import geometry\n",
    "\n",
    "def plot(unstacked_data, outfile=None, vmin=None, vmax=None):\n",
    "    cm = 1/2.54  # centimeters in inches\n",
    "    fig = plt.figure(figsize=(40*cm, 25*cm))\n",
    "    ax = plt.axes(projection=ccrs.Mollweide())\n",
    "    # ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "    ax.set_global()\n",
    "    unstacked_data.plot.contourf(levels=30, ax=ax, transform=ccrs.PlateCarree(),\n",
    "                                vmin=vmin, vmax=vmax, cmap='RdBu_r',\n",
    "                               cbar_kwargs={'ticks': [-30, -20, -10, 0, 10, 20, 30],\n",
    "                                           'label': 'temperature'})\n",
    "    ax.coastlines()    \n",
    "    if outfile is not None: plt.savefig(outfile, bbox_inches='tight', dpi=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b83a7c-1fb0-428a-8f0d-259f4fec3512",
   "metadata": {},
   "outputs": [],
   "source": [
    "unstacked_updated_mean_aao = helper_filter.dataset_mean.unstack_window_vector(mean_updated_aao.compute(), time=assimilation_date, variable_name='temperature')\n",
    "plot(unstacked_updated_mean_aao, vmin=-40, vmax=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ed872d-6cca-4ef9-83d7-ff5ae8045d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "unstacked_updated_mean_seq = helper_filter.dataset_mean.unstack_window_vector(mean_updated_seq, time=assimilation_date, variable_name='temperature')\n",
    "plot(unstacked_updated_mean_seq, vmin=-40, vmax=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a9b724-3242-4b01-9cc1-a66dbc20c536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot difference.\n",
    "plot(unstacked_updated_mean_aao - unstacked_updated_mean_seq, vmin=-7, vmax=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f05a39-1b0f-41c6-98a4-5394708c4abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original data (before updating.\n",
    "unstacked_mean = helper_filter.dataset_mean.unstack_window_vector(mean_ds.values.reshape(-1), time=assimilation_date, variable_name='temperature')\n",
    "plot(unstacked_mean, vmin=-40, vmax=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6e7e6a-7c51-4367-8f1f-af2512da887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot station data.\n",
    "df = data_month_ds.to_dataframe()\n",
    "# Could reset coordinates if you really wanted\n",
    "# df = df.reset_index()\n",
    "cm = 1/2.54  # centimeters in inches\n",
    "fig = plt.figure(figsize=(40*cm, 25*cm))\n",
    "ax = plt.axes(projection=ccrs.Mollweide())\n",
    "ax.set_global()\n",
    "    \n",
    "ax.coastlines()  \n",
    "\n",
    "df.plot.scatter('longitude', 'latitude', c=data_month_ds.name, cmap='jet', ax=ax, transform=ccrs.PlateCarree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107ed9b2-3b83-4c61-a331-2e1cd46f6703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot error wrt reference.\n",
    "plot(unstacked_updated_mean_aao - dataset_reference.temperature.sel(time=assimilation_date), vmin=-7, vmax=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6d003d-aa35-4f0f-9f07-56c734ba4004",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(unstacked_updated_mean_seq - dataset_reference.temperature.sel(time=assimilation_date), vmin=-7, vmax=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf2ad55-f006-4d05-96cd-8fff375ceeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original error.\n",
    "plot(unstacked_mean - dataset_reference.temperature.sel(time=assimilation_date), vmin=-7, vmax=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30436ee",
   "metadata": {},
   "source": [
    "## Compute accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46446e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diesel.scoring import compute_RE_score, compute_CRPS, compute_energy_score, compute_RMSE\n",
    "\n",
    "compute_RMSE(mean_ds.values, stacked_ref, min_lat=-70, max_lat=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc777d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = dataset_reference.temperature.sel(time=assimilation_date)\n",
    "stacked_ref = ref.stack(stacked_dim=('latitude', 'longitude'))\n",
    "\n",
    "stacked_prior_mean = unstacked_mean.stack(stacked_dim=('latitude', 'longitude'))\n",
    "stacked_updated_mean_seq = unstacked_updated_mean_seq.stack(stacked_dim=('latitude', 'longitude'))\n",
    "stacked_updated_mean_aao = unstacked_updated_mean_aao.stack(stacked_dim=('latitude', 'longitude'))\n",
    "\n",
    "print(compute_RMSE(stacked_prior_mean.values, stacked_ref, min_lat=-70, max_lat=70))\n",
    "print(compute_RMSE(stacked_updated_mean_seq.values, stacked_ref, min_lat=-70, max_lat=70))\n",
    "print(compute_RMSE(stacked_updated_mean_aao.values, stacked_ref, min_lat=-70, max_lat=70))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf3f92f-aa8e-4236-a5a0-8bd23724edb1",
   "metadata": {},
   "source": [
    "## Save results (updated temperature fields)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d484772-c43c-4fee-9125-88a0d1145e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_means_aao, updated_means_seq, prior_means = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c252f47-144b-4a74-85cb-e6c4987169d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_means_aao.append(unstacked_updated_mean_aao.copy())\n",
    "updated_means_seq.append(unstacked_updated_mean_seq.copy())\n",
    "prior_means.append(unstacked_mean.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ce350f-f145-4873-a0c4-72b66dc7c558",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.concat(updated_means_aao, dim='time')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
